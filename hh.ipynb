{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdipourasl/OCD/blob/main/hh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo0oSLpWgzl6",
        "outputId": "bfbfdc2d-9863-4a8a-da74-23b789fc9222"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.2)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.5.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "from google.colab import drive\n",
        "%matplotlib inline\n",
        "import os\n",
        "import os.path as op\n",
        "!pip install mne\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "data_dir= '/content/drive/My Drive/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQPNR08rglpt"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<h1>EEG Preprocessing with MNE</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDdJFcJpglpw"
      },
      "source": [
        "### 1. Importing Raw  Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c33rggLbglpx"
      },
      "outputs": [],
      "source": [
        "examples_dir = os.path.join('/content/drive/My Drive/','OCD_subj46.EDF')  # Path to the raw EEG Data folder\n",
        "raw = mne.io.read_raw_edf(os.path.join('/content/drive/My Drive/','OCD_subj46.EDF'))                                                         # Loading continuous data\n",
        "print(raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw.crop(tmin=5., tmax=50.)"
      ],
      "metadata": {
        "id": "j5jKNWfZ_UkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frg_RlRrglpy"
      },
      "source": [
        "### 2. Downsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWCyfwkGglpy"
      },
      "outputs": [],
      "source": [
        "raw.resample(250, npad=\"auto\")    # set sampling frequency to 256 points per second"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Channel Selection"
      ],
      "metadata": {
        "id": "Ols3hyM7AWN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw.pick_channels(['Fp1','Fp2','F7','F3','F4','F8','T3','C3','C4','T4','T5','P3','P4','T6','O1','O2','Fz','Cz','Pz'],ordered=True)"
      ],
      "metadata": {
        "id": "eQt6qZ-cqv0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw.info[\"ch_names\"])\n",
        "print(raw)"
      ],
      "metadata": {
        "id": "bSZ50llx1yyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBC3-VQglpy"
      },
      "source": [
        ">according to the Nyquist frequency, sampling rate should be at least two times of frequency.\n",
        "Moreover, 128 points are suitable and 256 points are desirable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD8SLgBaglpz"
      },
      "source": [
        "### 4. Rereference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3Psp1seglpz"
      },
      "outputs": [],
      "source": [
        "raw.set_eeg_reference('average', projection=True).apply_proj()  # re-referencing with the virtual average reference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Clean Data - ASR\n",
        "\n"
      ],
      "metadata": {
        "id": "Qij8Y71pANJU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6jiu5F9epZh"
      },
      "source": [
        "raw_uncleaned = raw.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssp_projectors = raw.info[\"projs\"]\n",
        "raw.del_proj()"
      ],
      "metadata": {
        "id": "8CP5rgZfmIml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1gtYAXve6Nc"
      },
      "source": [
        "First of all, we initialize an instance of the `ASR` class, which stores predefined parameters (like the rejection threshold), the functional procedures as well as the parameters matrices that are used to transform data.\n",
        "\n",
        "If you are familiar with [scikit-learn](https://scikit-learn.org/stable/), you will notice that a lot of MNE's automated cleaning and decoding functions work similar to scikit learn and can usually be seamlessly integrated into sklearn pipelines (which is due to the fact that some of the MNE developers also work on sklearn). This is especially helpful for brain decoding and BCI applications.\n",
        "\n",
        "At initialization our ASR instance needs to know the sampling frequency of our raw data (which is required for multiple features of the algorithms). We also tell it to repair portions of data whose variance is 5 standard deviations larger than the reference data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U autoreject\n",
        "!pip install https://api.github.com/repos/autoreject/autoreject/zipball/master\n",
        "#python -c 'import autoreject'\n",
        "from autoreject import AutoReject\n",
        "ar = AutoReject()\n",
        "epochs_clean = ar.fit_transform(epochs)  # doctest: +SKIP\n",
        "from autoreject import get_rejection_threshold\n",
        "reject = get_rejection_threshold(epochs)  # doctest: +SKIP"
      ],
      "metadata": {
        "id": "YWE3Lj60qKWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKYVhOwLrUn"
      },
      "source": [
        "!pip install asrpy -q\n",
        "from asrpy import ASR\n",
        "asr = ASR(sfreq=raw.info[\"sfreq\"], cutoff=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUvZRjTOfdjM"
      },
      "source": [
        "Now we fit our asr object to the data.\n",
        "\n",
        "We will use our entire raw data to fit. If your dataset is too large, you could also just use a fraction of the data for fitting. Theoretically, you could fit your cleaning algorithm to one dataset and then apply it to another, but this is very unusual and only makes sense for very specific experimental setups."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asr.fit(raw)"
      ],
      "metadata": {
        "id": "Wxi0jNGmtnF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLpfKti1fd4k"
      },
      "source": [
        "After our `asr` object was fitted to a certain dataset, we can apply it to our recorded raw data. The uncleaned data is transformed (/interpolated) according to the ASR procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtobA0xKfeA8"
      },
      "source": [
        "raw._data = asr.transform(raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPEeZL6dOD91"
      },
      "source": [
        "scalings= {\"eeg\":2e-5}\n",
        "\n",
        "print(\"Uncleaned data\")\n",
        "raw_uncleaned.plot(scalings=scalings);\n",
        "\n",
        "print(\"Cleaned data\")\n",
        "raw._data.plot(start=0.25, scalings=scalings);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpGl00B5glpz"
      },
      "source": [
        "### 6. Filtering the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hntlzsPHglpz"
      },
      "outputs": [],
      "source": [
        "raw.filter(1, 30, fir_design='firwin', picks=['eeg'])  # band-pass filter from 1 to 30 frequency over just\n",
        "                                                       # EEG channel and not EEG channel\n",
        "raw.plot_psd(fmax=100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Y_exhTglpz"
      },
      "source": [
        ">Lw-pass filter with 1 Hz cutoff frequency for removing low-frequency drifts.\n",
        "    High-pass filter with 30 Hz cutoff frequency for deteriorating the effect of\n",
        "    the AC power line frequency, cell phones, the geomagnetic field and so forth.\n",
        "    Therefore, a band-pass filter was used in the range 1Hz-30Hz with one step.\n",
        "    You can apply another band pass filter due to your own assumtions and hypotheses.\n",
        "    I recommend that band pass filtering would be better to occurr before the EEG\n",
        "    data epoching and artifact removal with ICA."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw.notch_filter(freqs=[16.667, 50]); # bandstop the train and power grid"
      ],
      "metadata": {
        "id": "thDHjJQWCX6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw.plot_psd(fmax=100);"
      ],
      "metadata": {
        "id": "RFMi28e_B8O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebIhHQ-gglpz"
      },
      "source": [
        "### 7. Visual Inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZS7KO2glpz"
      },
      "source": [
        "###### 7.1 Plot continuous data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LrUCNTqglpz"
      },
      "outputs": [],
      "source": [
        "#%matplotlib qt\n",
        "raw.plot()       # plot the EEG data. Use the '%matplotlib qt' to see\n",
        "                 # the data in a bright way and move conveniently"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAihXrrEglpz"
      },
      "source": [
        ">Use of visual inspection to reject some segments which have abnormal frequency,\n",
        "     signal discontinuous, abrupt jumping, irrelevant-task and son on.\n",
        "     Trace all EEG channels during time.\n",
        "     The best way to remove segtion of the data is deleting annotations in the segtion.\n",
        "     In addition, when you see irrelavant task or noise segemt in specefict channel,\n",
        "     you shoud remove the sement in all channels\n",
        "     Afterward, The instances of noisy segment which should be removed are created by\n",
        "     providing a EXCELL file with two columns of onsets and  offsets with descriptions\n",
        "     for each segment. The onsets and offsets are marked as seconds. onset refers to time\n",
        "     from start of the data. offset refers to time from end of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_DhLLj8glpz"
      },
      "source": [
        "###### 7.2 channel bad correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSTv8FROglp0"
      },
      "outputs": [],
      "source": [
        "#raw.info['bads'] = ['Fp1','Fp2','Fpz']         # Select bad channels visually to interpolate them with channels\n",
        "                                               # Sleceted channels are not real\n",
        "raw = raw.interpolate_bads(reset_bads=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfPLCLmTglp0"
      },
      "source": [
        "###### 7.3 Delete annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "YaGo594gglp0"
      },
      "outputs": [],
      "source": [
        "visual_inspection = pd.read_csv(examples_dir + \"\\\\sub-005_visual_inspection.csv\")  # Path to annotation folder\n",
        "                                                                                  # remove each segment with start and end time\n",
        "for i in range(visual_inspection.shape[0]):\n",
        "    result = np.where((mne.events_from_annotations(raw)[0][:,0] > visual_inspection['Start'][i]*256) &\n",
        "                      (mne.events_from_annotations(raw)[0][:,0] < visual_inspection['End'][i]*256));\n",
        "    raw.annotations.delete(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS8ShRY0glp0"
      },
      "outputs": [],
      "source": [
        "raw.plot()    # Let's see the data again to be sure that the noisy segemnts have been deleted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9CxXUwvglp0"
      },
      "source": [
        "### 8. Segmenting continuous data into epochs and setting Ampilitude ceriteria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deXKUfpjglp0"
      },
      "outputs": [],
      "source": [
        "events_from_annot, event_dict = mne.events_from_annotations(raw)# Get events and event_id from an Annotations object.\n",
        "event_dict = {'74':74, '75':75, '76':76}                        # Event dictionaries to extract epochs from continuous data,\n",
        "reject_criteria = dict(eeg=100e-6)                              # Absolute Amplitude of each epoch sould be smaller than 100 μV\n",
        "                                                                # tmin is start time before event, tmax is end time after event\n",
        "                                                                # - 100 ms (baseline) of cue's onset to 600 ms\n",
        "epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict, tmin=-0.1, tmax=1.6,\n",
        "                    reject=reject_criteria, baseline = (None,0), preload=True, picks=['eeg'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 9. Connectivity\n",
        "\n"
      ],
      "metadata": {
        "id": "9XezPmHmulK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U mne-connectivity\n",
        "import mne_connectivity\n"
      ],
      "metadata": {
        "id": "00unmx9hus58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " mne_connectivity.SpectralConnectivity(raw, freqs=(8., 20.), n_nodes=19, names=None, indices='all', method='plv', spec_method=None, n_epochs_used=None)"
      ],
      "metadata": {
        "id": "qufKBhAK9Kx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=mne_connectivity.spectral_connectivity_time(raw, freqs=(8., 20.), method='plv', average=False, indices=None, sfreq=raw.info[\"sfreq\"], fmin=None, fmax=None, fskip=0, faverage=False, sm_times=0, sm_freqs=1)\n"
      ],
      "metadata": {
        "id": "EbVb6xWt9heh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}